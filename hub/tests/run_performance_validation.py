#!/usr/bin/env python3
"""
æ€§èƒ½éªŒè¯è„šæœ¬
ç”¨äºéªŒè¯ä¿®å¤åçš„æµ‹è¯•æ¡†æ¶æ€§èƒ½æ˜¯å¦è¾¾åˆ°é¢„æœŸç›®æ ‡

ä½¿ç”¨æ–¹æ³•:
1. å¯åŠ¨æœåŠ¡: uvicorn main:app --host 0.0.0.0 --port 8000
2. è¿è¡ŒéªŒè¯: python hub/tests/run_performance_validation.py
"""

import asyncio
import sys
import os
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from hub.tests.common.http_client import BASE_URL, get_sync_client, get_async_client
from hub.tests.common.benchmark_utils import (
    warmup_connection, benchmark_invalid_intent_sync, 
    benchmark_invalid_intent_async, concurrent_benchmark
)
from hub.tests.common.report_generator import BenchmarkReportGenerator


def check_server_availability():
    """æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦å¯ç”¨"""
    print("ğŸ” æ£€æŸ¥æœåŠ¡å™¨å¯ç”¨æ€§...")
    
    client = get_sync_client()
    try:
        response = client.get("/")
        if response.status_code in [200, 404]:
            print("âœ… æœåŠ¡å™¨å¯ç”¨")
            return True
        else:
            print(f"âš ï¸ æœåŠ¡å™¨å“åº”å¼‚å¸¸: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ æœåŠ¡å™¨ä¸å¯ç”¨: {e}")
        print("è¯·ç¡®ä¿è¿è¡Œ: uvicorn main:app --host 0.0.0.0 --port 8000")
        return False


async def run_performance_validation():
    """è¿è¡Œæ€§èƒ½éªŒè¯æµ‹è¯•"""
    print("="*80)
    print("ğŸš€ æ— æ•ˆIntentæ€§èƒ½ä¿®å¤éªŒè¯")
    print("="*80)
    print(f"â° æµ‹è¯•å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ¯ ç›®æ ‡: å°†æ— æ•ˆIntentå“åº”æ—¶é—´ä»~2sé™ä½åˆ°â‰¤300ms")
    print(f"ğŸŒ æµ‹è¯•ç«¯ç‚¹: {BASE_URL}")
    print()
    
    # æ£€æŸ¥æœåŠ¡å™¨å¯ç”¨æ€§
    if not check_server_availability():
        return False
    
    try:
        # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
        report_generator = BenchmarkReportGenerator()
        
        print("ğŸ“Š æ‰§è¡ŒåŸºå‡†æµ‹è¯•...")
        print()
        
        # 1. åŒæ­¥åŸºå‡†æµ‹è¯•
        print("1ï¸âƒ£ åŒæ­¥åŸºå‡†æµ‹è¯•")
        sync_start = time.perf_counter()
        sync_result = benchmark_invalid_intent_sync(iterations=10)
        sync_duration = time.perf_counter() - sync_start
        
        # 2. å¼‚æ­¥åŸºå‡†æµ‹è¯•
        print("\n2ï¸âƒ£ å¼‚æ­¥åŸºå‡†æµ‹è¯•")
        async_start = time.perf_counter()
        async_result = await benchmark_invalid_intent_async(iterations=10)
        async_duration = time.perf_counter() - async_start
        
        # 3. å¹¶å‘åŸºå‡†æµ‹è¯•
        print("\n3ï¸âƒ£ å¹¶å‘åŸºå‡†æµ‹è¯•")
        concurrent_start = time.perf_counter()
        concurrent_result = await concurrent_benchmark(
            concurrent_workers=8,
            total_requests=40,
            batch_size=5
        )
        concurrent_duration = time.perf_counter() - concurrent_start
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        print("\nğŸ“‹ ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š...")
        report_path = report_generator.generate_httpx_benchmark_report(
            sync_result=sync_result,
            async_result=async_result,
            concurrent_result=concurrent_result,
            curl_baseline_ms=210.0
        )
        
        # éªŒè¯ç»“æœ
        print("\n" + "="*80)
        print("âœ… éªŒè¯ç»“æœæ±‡æ€»")
        print("="*80)
        
        validation_passed = True
        
        # æ£€æŸ¥åŒæ­¥æ€§èƒ½
        print(f"ğŸ“ˆ åŒæ­¥åŸºå‡†æµ‹è¯•:")
        print(f"   â€¢ å¹³å‡å“åº”æ—¶é—´: {sync_result.avg_time_ms}ms")
        print(f"   â€¢ P95å“åº”æ—¶é—´: {sync_result.p95_ms}ms")
        print(f"   â€¢ æˆåŠŸç‡: {sync_result.successful_requests}/{sync_result.total_requests}")
        print(f"   â€¢ æµ‹è¯•è€—æ—¶: {sync_duration:.2f}s")
        
        sync_target_met = sync_result.avg_time_ms <= 300
        print(f"   â€¢ ç›®æ ‡è¾¾æˆ: {'âœ… æ˜¯' if sync_target_met else 'âŒ å¦'} (â‰¤300ms)")
        if not sync_target_met:
            validation_passed = False
        
        # æ£€æŸ¥å¼‚æ­¥æ€§èƒ½
        print(f"\nğŸ“ˆ å¼‚æ­¥åŸºå‡†æµ‹è¯•:")
        print(f"   â€¢ å¹³å‡å“åº”æ—¶é—´: {async_result.avg_time_ms}ms")
        print(f"   â€¢ P95å“åº”æ—¶é—´: {async_result.p95_ms}ms")
        print(f"   â€¢ æˆåŠŸç‡: {async_result.successful_requests}/{async_result.total_requests}")
        print(f"   â€¢ æµ‹è¯•è€—æ—¶: {async_duration:.2f}s")
        
        async_target_met = async_result.avg_time_ms <= 300
        print(f"   â€¢ ç›®æ ‡è¾¾æˆ: {'âœ… æ˜¯' if async_target_met else 'âŒ å¦'} (â‰¤300ms)")
        if not async_target_met:
            validation_passed = False
        
        # æ£€æŸ¥å¹¶å‘æ€§èƒ½
        if concurrent_result.get('timing_stats'):
            timing_stats = concurrent_result['timing_stats']
            overall_stats = concurrent_result['overall_stats']
            
            print(f"\nğŸ“ˆ å¹¶å‘åŸºå‡†æµ‹è¯•:")
            print(f"   â€¢ å¹³å‡å“åº”æ—¶é—´: {timing_stats['avg_time_ms']}ms")
            print(f"   â€¢ P95å“åº”æ—¶é—´: {timing_stats['p95_ms']}ms")
            print(f"   â€¢ æˆåŠŸç‡: {overall_stats['success_rate']}%")
            print(f"   â€¢ ååé‡: {overall_stats['requests_per_second']} req/s")
            print(f"   â€¢ æµ‹è¯•è€—æ—¶: {concurrent_duration:.2f}s")
            
            concurrent_p95_met = timing_stats['p95_ms'] <= 450
            concurrent_stability_met = overall_stats['success_rate'] == 100
            print(f"   â€¢ P95ç›®æ ‡è¾¾æˆ: {'âœ… æ˜¯' if concurrent_p95_met else 'âŒ å¦'} (â‰¤450ms)")
            print(f"   â€¢ ç¨³å®šæ€§ç›®æ ‡è¾¾æˆ: {'âœ… æ˜¯' if concurrent_stability_met else 'âŒ å¦'} (100%)")
            
            if not (concurrent_p95_met and concurrent_stability_met):
                validation_passed = False
        else:
            print(f"\nğŸ“ˆ å¹¶å‘åŸºå‡†æµ‹è¯•: âŒ å¤±è´¥")
            validation_passed = False
        
        # æ€§èƒ½å¯¹æ¯”
        print(f"\nğŸ“Š æ€§èƒ½æ”¹è¿›å¯¹æ¯”:")
        original_time = 2050  # åŸå§‹é—®é¢˜æ—¶é—´
        if sync_result.avg_time_ms > 0:
            improvement = ((original_time - sync_result.avg_time_ms) / original_time) * 100
            speedup = original_time / sync_result.avg_time_ms
            print(f"   â€¢ ä¿®å¤å‰: ~{original_time}ms")
            print(f"   â€¢ ä¿®å¤å: {sync_result.avg_time_ms}ms")
            print(f"   â€¢ æ€§èƒ½æå‡: {improvement:.1f}%")
            print(f"   â€¢ é€Ÿåº¦å€æ•°: {speedup:.1f}x")
        
        # æœ€ç»ˆç»“è®º
        print(f"\nğŸ¯ æœ€ç»ˆç»“è®º:")
        if validation_passed:
            print("âœ… æ€§èƒ½ä¿®å¤æˆåŠŸï¼æ‰€æœ‰éªŒæ”¶æ ‡å‡†å‡å·²è¾¾æˆ")
            print("ğŸ‰ æ— æ•ˆIntentå¤„ç†æ—¶é—´å·²ä»~2sé™ä½åˆ°é¢„æœŸèŒƒå›´å†…")
        else:
            print("âš ï¸ éƒ¨åˆ†éªŒæ”¶æ ‡å‡†æœªè¾¾æˆï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒä¼˜")
        
        print(f"\nğŸ“‹ è¯¦ç»†æŠ¥å‘Š: {report_path}")
        print(f"â° éªŒè¯å®Œæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        return validation_passed
        
    except Exception as e:
        print(f"âŒ éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # æ¸…ç†è¿æ¥
        from hub.tests.common.http_client import close_all_clients
        close_all_clients()


def main():
    """ä¸»å‡½æ•°"""
    success = asyncio.run(run_performance_validation())
    
    if success:
        print("\nğŸŠ éªŒè¯å®Œæˆï¼šæ€§èƒ½ä¿®å¤æˆåŠŸï¼")
        sys.exit(0)
    else:
        print("\nâŒ éªŒè¯å¤±è´¥ï¼šéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        sys.exit(1)


if __name__ == "__main__":
    main()
