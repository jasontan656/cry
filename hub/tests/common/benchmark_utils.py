#!/usr/bin/env python3
"""
Hub Tests Benchmark Utilities
è¿æ¥é¢„çƒ­å’Œæ€§èƒ½åŸºå‡†æµ‹è¯•å·¥å…·

æ ¹æ®ã€ŠInvalid Intent Slowpath Deep Dive Analysisã€‹æŠ¥å‘Šä¿®å¤ï¼š
- è¿æ¥é¢„çƒ­ï¼šè§£å†³é¦–æ¬¡è¯·æ±‚è¿æ¥å»ºç«‹å¼€é”€
- æ€§èƒ½åŸºå‡†ï¼šæä¾›æ ‡å‡†åŒ–çš„æ€§èƒ½æµ‹è¯•å’ŒæŠ¥å‘Š
- æ—¶é—´æµ‹é‡ï¼šé«˜ç²¾åº¦è®¡æ—¶å’Œåˆ†ä½æ•°ç»Ÿè®¡
- å¯¹ç…§æµ‹è¯•ï¼šä¸ curl åŸºå‡†å¯¹æ¯”åˆ†æ
"""

import time
import asyncio
import statistics
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from http_client import (
    get_sync_client, get_async_client, 
    safe_request_with_timeout_details,
    safe_async_request_with_timeout_details,
    BASE_URL
)


@dataclass
class BenchmarkResult:
    """åŸºå‡†æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    total_requests: int
    successful_requests: int
    failed_requests: int
    error_requests: int
    
    # æ—¶é—´ç»Ÿè®¡ï¼ˆæ¯«ç§’ï¼‰
    total_time_ms: float
    avg_time_ms: float
    min_time_ms: float
    max_time_ms: float
    p50_ms: float
    p90_ms: float
    p95_ms: float
    
    # è¿æ¥ç»Ÿè®¡
    connect_times_ms: List[float]
    process_times_ms: List[float]
    
    # é”™è¯¯è¯¦æƒ…
    timeout_errors: int
    connect_errors: int
    other_errors: int
    error_details: List[Dict[str, Any]]
    
    # æœåŠ¡ç«¯å¤„ç†æ—¶é—´ï¼ˆæ¥è‡ªå“åº”å¤´ï¼‰
    server_process_times_ms: List[float]


def warmup_connection(rounds: int = 2) -> Dict[str, Any]:
    """
    è¿æ¥é¢„çƒ­å‡½æ•°
    
    åœ¨æ€§èƒ½æµ‹è¯•å‰è°ƒç”¨ï¼Œé¢„çƒ­ TCP è¿æ¥å’Œè¿æ¥æ± ï¼Œå¿½ç•¥ç»“æœ
    
    Args:
        rounds: é¢„çƒ­è½®æ•°ï¼Œé»˜è®¤ 2 è½®
        
    Returns:
        é¢„çƒ­ç»“æœç»Ÿè®¡
    """
    print(f"ğŸ”¥ å¼€å§‹è¿æ¥é¢„çƒ­ ({rounds} è½®)...")
    
    warmup_results = []
    client = get_sync_client()
    
    # é¢„çƒ­ GET æ ¹è·¯å¾„
    for i in range(rounds):
        start_time = time.perf_counter()
        response, error = safe_request_with_timeout_details(client, "GET", "/")
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        
        warmup_results.append({
            "round": i + 1,
            "endpoint": "GET /",
            "success": response is not None,
            "time_ms": round(elapsed_ms, 2),
            "status_code": response.status_code if response else None,
            "error": error
        })
    
    # é¢„çƒ­ POST æ— æ•ˆ intent ç«¯ç‚¹
    for i in range(rounds):
        start_time = time.perf_counter()
        response, error = safe_request_with_timeout_details(
            client, "POST", "/dev/raise_invalid_intent", json={}
        )
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        
        warmup_results.append({
            "round": i + 1,
            "endpoint": "POST /dev/raise_invalid_intent",
            "success": response is not None,
            "time_ms": round(elapsed_ms, 2),
            "status_code": response.status_code if response else None,
            "error": error
        })
    
    successful_warmups = sum(1 for r in warmup_results if r["success"])
    avg_warmup_time = statistics.mean([r["time_ms"] for r in warmup_results if r["success"]])
    
    result = {
        "total_warmup_requests": len(warmup_results),
        "successful_warmups": successful_warmups,
        "avg_warmup_time_ms": round(avg_warmup_time, 2),
        "warmup_success_rate": round(successful_warmups / len(warmup_results) * 100, 2),
        "detailed_results": warmup_results
    }
    
    print(f"âœ… è¿æ¥é¢„çƒ­å®Œæˆ: {successful_warmups}/{len(warmup_results)} æˆåŠŸ, å¹³å‡ {result['avg_warmup_time_ms']}ms")
    return result


async def async_warmup_connection(rounds: int = 2) -> Dict[str, Any]:
    """å¼‚æ­¥è¿æ¥é¢„çƒ­å‡½æ•°"""
    print(f"ğŸ”¥ å¼€å§‹å¼‚æ­¥è¿æ¥é¢„çƒ­ ({rounds} è½®)...")
    
    warmup_results = []
    client = get_async_client()
    
    # é¢„çƒ­ GET æ ¹è·¯å¾„
    for i in range(rounds):
        start_time = time.perf_counter()
        response, error = await safe_async_request_with_timeout_details(client, "GET", "/")
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        
        warmup_results.append({
            "round": i + 1,
            "endpoint": "GET /",
            "success": response is not None,
            "time_ms": round(elapsed_ms, 2),
            "status_code": response.status_code if response else None,
            "error": error
        })
    
    # é¢„çƒ­ POST æ— æ•ˆ intent ç«¯ç‚¹
    for i in range(rounds):
        start_time = time.perf_counter()
        response, error = await safe_async_request_with_timeout_details(
            client, "POST", "/dev/raise_invalid_intent", json={}
        )
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        
        warmup_results.append({
            "round": i + 1,
            "endpoint": "POST /dev/raise_invalid_intent",
            "success": response is not None,
            "time_ms": round(elapsed_ms, 2),
            "status_code": response.status_code if response else None,
            "error": error
        })
    
    successful_warmups = sum(1 for r in warmup_results if r["success"])
    avg_warmup_time = statistics.mean([r["time_ms"] for r in warmup_results if r["success"]])
    
    result = {
        "total_warmup_requests": len(warmup_results),
        "successful_warmups": successful_warmups,
        "avg_warmup_time_ms": round(avg_warmup_time, 2),
        "warmup_success_rate": round(successful_warmups / len(warmup_results) * 100, 2),
        "detailed_results": warmup_results
    }
    
    print(f"âœ… å¼‚æ­¥è¿æ¥é¢„çƒ­å®Œæˆ: {successful_warmups}/{len(warmup_results)} æˆåŠŸ, å¹³å‡ {result['avg_warmup_time_ms']}ms")
    return result


def benchmark_invalid_intent_sync(iterations: int = 10) -> BenchmarkResult:
    """
    åŒæ­¥æ— æ•ˆ intent åŸºå‡†æµ‹è¯•
    
    æµ‹è¯• /intent ç«¯ç‚¹å¤„ç†æ— æ•ˆ intent çš„æ€§èƒ½
    
    Args:
        iterations: æµ‹è¯•è¿­ä»£æ¬¡æ•°
        
    Returns:
        BenchmarkResult: è¯¦ç»†çš„åŸºå‡†æµ‹è¯•ç»“æœ
    """
    print(f"ğŸ“Š å¼€å§‹åŒæ­¥æ— æ•ˆ intent åŸºå‡†æµ‹è¯• ({iterations} æ¬¡è¿­ä»£)...")
    
    # å…ˆè¿›è¡Œé¢„çƒ­
    warmup_connection(2)
    
    client = get_sync_client()
    test_request = {
        "intent": "benchmark_test_intent",
        "request_id": "benchmark_sync_001",
        "user_id": "benchmark_user"
    }
    
    results = []
    error_details = []
    
    for i in range(iterations):
        start_time = time.perf_counter()
        response, error = safe_request_with_timeout_details(
            client, "POST", "/intent", json=test_request
        )
        total_time_ms = (time.perf_counter() - start_time) * 1000
        
        if response:
            # æå–æœåŠ¡ç«¯å¤„ç†æ—¶é—´ï¼ˆå¦‚æœå­˜åœ¨ X-Process-Time å¤´ï¼‰
            server_time_ms = None
            if "X-Process-Time" in response.headers:
                try:
                    server_time_ms = float(response.headers["X-Process-Time"]) * 1000
                except:
                    pass
            
            results.append({
                "iteration": i + 1,
                "total_time_ms": round(total_time_ms, 2),
                "server_time_ms": round(server_time_ms, 2) if server_time_ms else None,
                "status_code": response.status_code,
                "success": True,
                "error": False
            })
        else:
            results.append({
                "iteration": i + 1,
                "total_time_ms": round(total_time_ms, 2),
                "server_time_ms": None,
                "status_code": None,
                "success": False,
                "error": True
            })
            error_details.append(error)
    
    # ç»Ÿè®¡åˆ†æ
    successful_results = [r for r in results if r["success"]]
    failed_results = [r for r in results if not r["success"]]
    
    if successful_results:
        times_ms = [r["total_time_ms"] for r in successful_results]
        server_times_ms = [r["server_time_ms"] for r in successful_results if r["server_time_ms"]]
        
        # è®¡ç®—åˆ†ä½æ•°
        times_ms_sorted = sorted(times_ms)
        p50_idx = int(len(times_ms_sorted) * 0.5)
        p90_idx = int(len(times_ms_sorted) * 0.9)
        p95_idx = int(len(times_ms_sorted) * 0.95)
        
        benchmark_result = BenchmarkResult(
            total_requests=iterations,
            successful_requests=len(successful_results),
            failed_requests=len(failed_results),
            error_requests=len([r for r in results if r.get("error", False)]),
            
            total_time_ms=round(sum(times_ms), 2),
            avg_time_ms=round(statistics.mean(times_ms), 2),
            min_time_ms=round(min(times_ms), 2),
            max_time_ms=round(max(times_ms), 2),
            p50_ms=round(times_ms_sorted[p50_idx], 2),
            p90_ms=round(times_ms_sorted[p90_idx], 2),
            p95_ms=round(times_ms_sorted[p95_idx], 2),
            
            connect_times_ms=[],  # æš‚æ—¶æ— æ³•å•ç‹¬æµ‹é‡è¿æ¥æ—¶é—´
            process_times_ms=times_ms,
            
            timeout_errors=len([e for e in error_details if e and e.get("error_type") == "timeout"]),
            connect_errors=len([e for e in error_details if e and e.get("error_type") == "connect"]),
            other_errors=len([e for e in error_details if e and e.get("error_type") not in ["timeout", "connect"]]),
            error_details=error_details,
            
            server_process_times_ms=server_times_ms
        )
        
        print(f"âœ… åŒæ­¥åŸºå‡†æµ‹è¯•å®Œæˆ: å¹³å‡ {benchmark_result.avg_time_ms}ms, P95 {benchmark_result.p95_ms}ms")
        return benchmark_result
    else:
        print("âŒ æ‰€æœ‰è¯·æ±‚å‡å¤±è´¥ï¼Œæ— æ³•ç”ŸæˆåŸºå‡†ç»“æœ")
        return BenchmarkResult(
            total_requests=iterations,
            successful_requests=0,
            failed_requests=iterations,
            error_requests=iterations,
            total_time_ms=0, avg_time_ms=0, min_time_ms=0, max_time_ms=0,
            p50_ms=0, p90_ms=0, p95_ms=0,
            connect_times_ms=[], process_times_ms=[],
            timeout_errors=len([e for e in error_details if e and e.get("error_type") == "timeout"]),
            connect_errors=len([e for e in error_details if e and e.get("error_type") == "connect"]),
            other_errors=len([e for e in error_details if e and e.get("error_type") not in ["timeout", "connect"]]),
            error_details=error_details,
            server_process_times_ms=[]
        )


async def benchmark_invalid_intent_async(iterations: int = 10) -> BenchmarkResult:
    """å¼‚æ­¥æ— æ•ˆ intent åŸºå‡†æµ‹è¯•"""
    print(f"ğŸ“Š å¼€å§‹å¼‚æ­¥æ— æ•ˆ intent åŸºå‡†æµ‹è¯• ({iterations} æ¬¡è¿­ä»£)...")
    
    # å…ˆè¿›è¡Œé¢„çƒ­
    await async_warmup_connection(2)
    
    client = get_async_client()
    test_request = {
        "intent": "benchmark_test_intent",
        "request_id": "benchmark_async_001", 
        "user_id": "benchmark_user"
    }
    
    results = []
    error_details = []
    
    for i in range(iterations):
        start_time = time.perf_counter()
        response, error = await safe_async_request_with_timeout_details(
            client, "POST", "/intent", json=test_request
        )
        total_time_ms = (time.perf_counter() - start_time) * 1000
        
        if response:
            # æå–æœåŠ¡ç«¯å¤„ç†æ—¶é—´
            server_time_ms = None
            if "X-Process-Time" in response.headers:
                try:
                    server_time_ms = float(response.headers["X-Process-Time"]) * 1000
                except:
                    pass
            
            results.append({
                "iteration": i + 1,
                "total_time_ms": round(total_time_ms, 2),
                "server_time_ms": round(server_time_ms, 2) if server_time_ms else None,
                "status_code": response.status_code,
                "success": True,
                "error": False
            })
        else:
            results.append({
                "iteration": i + 1,
                "total_time_ms": round(total_time_ms, 2),
                "server_time_ms": None,
                "status_code": None,
                "success": False,
                "error": True
            })
            error_details.append(error)
    
    # ç»Ÿè®¡åˆ†æï¼ˆåŒæ­¥ç‰ˆæœ¬é€»è¾‘ï¼‰
    successful_results = [r for r in results if r["success"]]
    failed_results = [r for r in results if not r["success"]]
    
    if successful_results:
        times_ms = [r["total_time_ms"] for r in successful_results]
        server_times_ms = [r["server_time_ms"] for r in successful_results if r["server_time_ms"]]
        
        times_ms_sorted = sorted(times_ms)
        p50_idx = int(len(times_ms_sorted) * 0.5)
        p90_idx = int(len(times_ms_sorted) * 0.9)
        p95_idx = int(len(times_ms_sorted) * 0.95)
        
        benchmark_result = BenchmarkResult(
            total_requests=iterations,
            successful_requests=len(successful_results),
            failed_requests=len(failed_results),
            error_requests=len([r for r in results if r.get("error", False)]),
            
            total_time_ms=round(sum(times_ms), 2),
            avg_time_ms=round(statistics.mean(times_ms), 2),
            min_time_ms=round(min(times_ms), 2),
            max_time_ms=round(max(times_ms), 2),
            p50_ms=round(times_ms_sorted[p50_idx], 2),
            p90_ms=round(times_ms_sorted[p90_idx], 2),
            p95_ms=round(times_ms_sorted[p95_idx], 2),
            
            connect_times_ms=[],
            process_times_ms=times_ms,
            
            timeout_errors=len([e for e in error_details if e and e.get("error_type") == "timeout"]),
            connect_errors=len([e for e in error_details if e and e.get("error_type") == "connect"]),
            other_errors=len([e for e in error_details if e and e.get("error_type") not in ["timeout", "connect"]]),
            error_details=error_details,
            
            server_process_times_ms=server_times_ms
        )
        
        print(f"âœ… å¼‚æ­¥åŸºå‡†æµ‹è¯•å®Œæˆ: å¹³å‡ {benchmark_result.avg_time_ms}ms, P95 {benchmark_result.p95_ms}ms")
        return benchmark_result
    else:
        print("âŒ æ‰€æœ‰å¼‚æ­¥è¯·æ±‚å‡å¤±è´¥ï¼Œæ— æ³•ç”ŸæˆåŸºå‡†ç»“æœ")
        return BenchmarkResult(
            total_requests=iterations,
            successful_requests=0,
            failed_requests=iterations,
            error_requests=iterations,
            total_time_ms=0, avg_time_ms=0, min_time_ms=0, max_time_ms=0,
            p50_ms=0, p90_ms=0, p95_ms=0,
            connect_times_ms=[], process_times_ms=[],
            timeout_errors=len([e for e in error_details if e and e.get("error_type") == "timeout"]),
            connect_errors=len([e for e in error_details if e and e.get("error_type") == "connect"]),
            other_errors=len([e for e in error_details if e and e.get("error_type") not in ["timeout", "connect"]]),
            error_details=error_details,
            server_process_times_ms=[]
        )


async def concurrent_benchmark(
    concurrent_workers: int = 8,
    total_requests: int = 40,
    batch_size: int = 5
) -> Dict[str, Any]:
    """
    å¹¶å‘åŸºå‡†æµ‹è¯•
    
    Args:
        concurrent_workers: å¹¶å‘å·¥ä½œè€…æ•°é‡
        total_requests: æ€»è¯·æ±‚æ•°
        batch_size: æ¯æ‰¹è¯·æ±‚æ•°
        
    Returns:
        å¹¶å‘æµ‹è¯•ç»“æœå­—å…¸
    """
    print(f"ğŸš€ å¼€å§‹å¹¶å‘åŸºå‡†æµ‹è¯•: {concurrent_workers} å¹¶å‘ Ã— {total_requests} è¯·æ±‚ (æ‰¹é‡ {batch_size})")
    
    # é¢„çƒ­
    await async_warmup_connection(2)
    
    client = get_async_client()
    
    # åˆ†æ‰¹æ‰§è¡Œ
    batches = []
    for i in range(0, total_requests, batch_size):
        batch_requests = []
        for j in range(min(batch_size, total_requests - i)):
            req_id = i + j + 1
            batch_requests.append({
                "intent": "benchmark_test_intent",
                "request_id": f"concurrent_bench_{req_id}",
                "user_id": f"concurrent_user_{req_id}"
            })
        batches.append(batch_requests)
    
    all_results = []
    total_start_time = time.perf_counter()
    
    for batch_idx, batch_requests in enumerate(batches):
        print(f"ğŸ”„ æ‰§è¡Œæ‰¹æ¬¡ {batch_idx + 1}/{len(batches)} ({len(batch_requests)} è¯·æ±‚)")
        
        # åˆ›å»ºä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(concurrent_workers)
        
        async def execute_request(request_data: Dict[str, Any]) -> Dict[str, Any]:
            async with semaphore:
                start_time = time.perf_counter()
                response, error = await safe_async_request_with_timeout_details(
                    client, "POST", "/intent", json=request_data
                )
                total_time_ms = (time.perf_counter() - start_time) * 1000
                
                if response:
                    server_time_ms = None
                    if "X-Process-Time" in response.headers:
                        try:
                            server_time_ms = float(response.headers["X-Process-Time"]) * 1000
                        except:
                            pass
                    
                    return {
                        "request_id": request_data["request_id"],
                        "total_time_ms": round(total_time_ms, 2),
                        "server_time_ms": round(server_time_ms, 2) if server_time_ms else None,
                        "status_code": response.status_code,
                        "success": True,
                        "error": None
                    }
                else:
                    return {
                        "request_id": request_data["request_id"],
                        "total_time_ms": round(total_time_ms, 2),
                        "server_time_ms": None,
                        "status_code": None,
                        "success": False,
                        "error": error
                    }
        
        # æ‰§è¡Œå½“å‰æ‰¹æ¬¡çš„å¹¶å‘è¯·æ±‚
        batch_tasks = [execute_request(req) for req in batch_requests]
        batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        for i, result in enumerate(batch_results):
            if isinstance(result, Exception):
                all_results.append({
                    "request_id": batch_requests[i]["request_id"],
                    "total_time_ms": 0,
                    "server_time_ms": None,
                    "status_code": None,
                    "success": False,
                    "error": {"error_type": "exception", "message": str(result)}
                })
            else:
                all_results.append(result)
    
    total_time_seconds = time.perf_counter() - total_start_time
    
    # ç»Ÿè®¡åˆ†æ
    successful_results = [r for r in all_results if r["success"]]
    failed_results = [r for r in all_results if not r["success"]]
    
    if successful_results:
        times_ms = [r["total_time_ms"] for r in successful_results]
        server_times_ms = [r["server_time_ms"] for r in successful_results if r["server_time_ms"]]
        
        times_ms_sorted = sorted(times_ms)
        p50_idx = int(len(times_ms_sorted) * 0.5)
        p90_idx = int(len(times_ms_sorted) * 0.9)
        p95_idx = int(len(times_ms_sorted) * 0.95)
        
        result = {
            "test_config": {
                "concurrent_workers": concurrent_workers,
                "total_requests": total_requests,
                "batch_size": batch_size,
                "total_batches": len(batches)
            },
            "overall_stats": {
                "total_requests": len(all_results),
                "successful_requests": len(successful_results),
                "failed_requests": len(failed_results),
                "success_rate": round(len(successful_results) / len(all_results) * 100, 2),
                "total_time_seconds": round(total_time_seconds, 3),
                "requests_per_second": round(len(all_results) / total_time_seconds, 2)
            },
            "timing_stats": {
                "avg_time_ms": round(statistics.mean(times_ms), 2),
                "min_time_ms": round(min(times_ms), 2),
                "max_time_ms": round(max(times_ms), 2),
                "p50_ms": round(times_ms_sorted[p50_idx], 2),
                "p90_ms": round(times_ms_sorted[p90_idx], 2),
                "p95_ms": round(times_ms_sorted[p95_idx], 2)
            },
            "server_timing": {
                "server_times_available": len(server_times_ms),
                "avg_server_time_ms": round(statistics.mean(server_times_ms), 2) if server_times_ms else None
            },
            "error_analysis": {
                "timeout_errors": len([r for r in all_results if r.get("error") and r["error"].get("error_type") == "timeout"]),
                "connect_errors": len([r for r in all_results if r.get("error") and r["error"].get("error_type") == "connect"]),
                "other_errors": len([r for r in all_results if r.get("error") and r["error"].get("error_type") not in ["timeout", "connect"]])
            }
        }
        
        print(f"âœ… å¹¶å‘åŸºå‡†æµ‹è¯•å®Œæˆ: {result['overall_stats']['success_rate']}% æˆåŠŸ, P95 {result['timing_stats']['p95_ms']}ms")
        return result
    else:
        print("âŒ æ‰€æœ‰å¹¶å‘è¯·æ±‚å‡å¤±è´¥")
        return {
            "test_config": {
                "concurrent_workers": concurrent_workers,
                "total_requests": total_requests,
                "batch_size": batch_size
            },
            "overall_stats": {
                "total_requests": len(all_results),
                "successful_requests": 0,
                "failed_requests": len(all_results),
                "success_rate": 0,
                "total_time_seconds": round(total_time_seconds, 3)
            },
            "error": "æ‰€æœ‰è¯·æ±‚å‡å¤±è´¥"
        }
