#!/usr/bin/env python3
"""
Hub Tests Report Generator
æ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨

ç”Ÿæˆè¯¦ç»†çš„åŸºå‡†æµ‹è¯•æŠ¥å‘Šï¼ŒåŒ…æ‹¬ä¸ curl åŸºå‡†çš„å¯¹æ¯”åˆ†æ
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
from benchmark_utils import BenchmarkResult


class BenchmarkReportGenerator:
    """åŸºå‡†æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, report_dir: str = "hub/tests/report"):
        self.report_dir = report_dir
        self.ensure_report_dir()
    
    def ensure_report_dir(self):
        """ç¡®ä¿æŠ¥å‘Šç›®å½•å­˜åœ¨"""
        os.makedirs(self.report_dir, exist_ok=True)
    
    def generate_httpx_benchmark_report(
        self,
        sync_result: Optional[BenchmarkResult] = None,
        async_result: Optional[BenchmarkResult] = None,
        concurrent_result: Optional[Dict[str, Any]] = None,
        curl_baseline_ms: float = 210.0
    ) -> str:
        """
        ç”Ÿæˆ httpx åŸºå‡†æµ‹è¯•æŠ¥å‘Š
        
        Args:
            sync_result: åŒæ­¥åŸºå‡†æµ‹è¯•ç»“æœ
            async_result: å¼‚æ­¥åŸºå‡†æµ‹è¯•ç»“æœ
            concurrent_result: å¹¶å‘åŸºå‡†æµ‹è¯•ç»“æœ
            curl_baseline_ms: curl åŸºå‡†å‚è€ƒå€¼ï¼ˆæ¯«ç§’ï¼‰
            
        Returns:
            ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        report_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        report_filename = f"httpx_benchmark_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        report_path = os.path.join(self.report_dir, report_filename)
        
        # ç”Ÿæˆ Markdown æŠ¥å‘Šå†…å®¹
        report_content = f"""# HttpX åŸºå‡†æµ‹è¯•æŠ¥å‘Š

## ğŸ“Š æ‰§è¡Œæ¦‚è¿°

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {report_time}  
**æµ‹è¯•ç›®æ ‡**: ä¿®å¤æ— æ•ˆ intent è¯·æ±‚è€—æ—¶é—®é¢˜ï¼Œä» ~2s é™ä½åˆ° ~210ms  
**å‚è€ƒåŸºå‡†**: curl ç›´æ¥æµ‹è¯• = {curl_baseline_ms}ms  
**éªŒæ”¶æ ‡å‡†**: å•æ¬¡å¹³å‡ â‰¤ 300msï¼Œå¹¶å‘ P95 â‰¤ 450ms

---

## ğŸ”§ æµ‹è¯•é…ç½®ä¿®å¤

### HttpX å®¢æˆ·ç«¯é…ç½®ä¼˜åŒ–
- **BASE_URL**: 127.0.0.1:8000 (é¿å… localhost DNS è§£æå»¶è¿Ÿ)
- **è¿æ¥è¶…æ—¶**: 1.0s (connect)
- **è¯»å†™è¶…æ—¶**: 4.0s (read/write/pool)  
- **è¿æ¥æ± **: 20 keepalive + 50 max connections
- **åè®®**: å¼ºåˆ¶ HTTP/1.1ï¼Œç¦ç”¨ HTTP/2
- **é‡è¯•**: ç¦ç”¨é‡è¯•æœºåˆ¶
- **ç¯å¢ƒ**: ç¦ç”¨ç³»ç»Ÿä»£ç†å’Œç¯å¢ƒå˜é‡å½±å“

### æµ‹è¯•æ¡†æ¶æ”¹è¿›
- **è¿æ¥é¢„çƒ­**: æ‰§è¡Œå‰é¢„çƒ­ TCP è¿æ¥æ± 
- **å®¢æˆ·ç«¯å¤ç”¨**: å…¨å¥—æµ‹è¯•ä½¿ç”¨å•ä¸€å®¢æˆ·ç«¯å®ä¾‹
- **è¶…æ—¶å¤„ç†**: è¯¦ç»†è¶…æ—¶é”™è¯¯åˆ†ç±»å’ŒæŠ¥å‘Š
- **å¹¶å‘æ§åˆ¶**: ä¿¡å·é‡é™åˆ¶ + æ‰¹é‡æ‰§è¡Œ

---
"""

        # æ·»åŠ åŒæ­¥æµ‹è¯•ç»“æœ
        if sync_result:
            report_content += self._generate_sync_section(sync_result, curl_baseline_ms)
        
        # æ·»åŠ å¼‚æ­¥æµ‹è¯•ç»“æœ
        if async_result:
            report_content += self._generate_async_section(async_result, curl_baseline_ms)
        
        # æ·»åŠ å¹¶å‘æµ‹è¯•ç»“æœ
        if concurrent_result:
            report_content += self._generate_concurrent_section(concurrent_result, curl_baseline_ms)
        
        # æ·»åŠ å¯¹æ¯”åˆ†æå’Œç»“è®º
        report_content += self._generate_comparison_and_conclusion(
            sync_result, async_result, concurrent_result, curl_baseline_ms
        )
        
        # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“‹ åŸºå‡†æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return report_path
    
    def _generate_sync_section(self, result: BenchmarkResult, curl_baseline: float) -> str:
        """ç”ŸæˆåŒæ­¥æµ‹è¯•ç»“æœç« èŠ‚"""
        performance_grade = "ä¼˜ç§€" if result.avg_time_ms <= 300 else "è‰¯å¥½" if result.avg_time_ms <= 500 else "éœ€è¦æ”¹è¿›"
        vs_curl_ratio = result.avg_time_ms / curl_baseline if curl_baseline > 0 else 0
        
        return f"""## ğŸ“ˆ åŒæ­¥åŸºå‡†æµ‹è¯•ç»“æœ

### åŸºç¡€æŒ‡æ ‡
| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |
|------|------|------|
| æ€»è¯·æ±‚æ•° | {result.total_requests} | - |
| æˆåŠŸè¯·æ±‚æ•° | {result.successful_requests} | {'âœ…' if result.successful_requests == result.total_requests else 'âš ï¸'} |
| æˆåŠŸç‡ | {(result.successful_requests/result.total_requests*100):.1f}% | {'âœ…' if result.successful_requests == result.total_requests else 'âš ï¸'} |

### å“åº”æ—¶é—´åˆ†æ
| ç»Ÿè®¡é‡ | æ—¶é—´ (ms) | vs CurlåŸºå‡† | çŠ¶æ€ |
|--------|-----------|-------------|------|
| å¹³å‡å€¼ | {result.avg_time_ms} | {vs_curl_ratio:.1f}x | {'âœ…' if result.avg_time_ms <= 300 else 'âš ï¸'} |
| ä¸­ä½æ•° (P50) | {result.p50_ms} | {result.p50_ms/curl_baseline:.1f}x | - |
| P90 | {result.p90_ms} | {result.p90_ms/curl_baseline:.1f}x | - |
| P95 | {result.p95_ms} | {result.p95_ms/curl_baseline:.1f}x | {'âœ…' if result.p95_ms <= 450 else 'âš ï¸'} |
| æœ€å°å€¼ | {result.min_time_ms} | {result.min_time_ms/curl_baseline:.1f}x | - |
| æœ€å¤§å€¼ | {result.max_time_ms} | {result.max_time_ms/curl_baseline:.1f}x | - |

### æ€§èƒ½è¯„çº§
**ç­‰çº§**: {performance_grade}  
**ä¸ Curl åŸºå‡†å¯¹æ¯”**: {vs_curl_ratio:.1f}x ({'+' if vs_curl_ratio > 1 else ''}{(vs_curl_ratio-1)*100:.1f}% å·®å¼‚)

### é”™è¯¯åˆ†æ
| é”™è¯¯ç±»å‹ | æ•°é‡ | å æ¯” |
|----------|------|------|
| è¶…æ—¶é”™è¯¯ | {result.timeout_errors} | {(result.timeout_errors/result.total_requests*100):.1f}% |
| è¿æ¥é”™è¯¯ | {result.connect_errors} | {(result.connect_errors/result.total_requests*100):.1f}% |
| å…¶ä»–é”™è¯¯ | {result.other_errors} | {(result.other_errors/result.total_requests*100):.1f}% |

### æœåŠ¡ç«¯å¤„ç†æ—¶é—´
"""
        
        if result.server_process_times_ms:
            avg_server_time = sum(result.server_process_times_ms) / len(result.server_process_times_ms)
            server_content = f"""
**å¯ç”¨æ ·æœ¬**: {len(result.server_process_times_ms)} ä¸ª  
**å¹³å‡æœåŠ¡ç«¯å¤„ç†æ—¶é—´**: {avg_server_time:.2f}ms  
**å®¢æˆ·ç«¯å¼€é”€**: {result.avg_time_ms - avg_server_time:.2f}ms ({((result.avg_time_ms - avg_server_time)/result.avg_time_ms*100):.1f}%)

"""
        else:
            server_content = f"""
**æœåŠ¡ç«¯æ—¶é—´**: æ— å¯ç”¨æ•°æ® (æœªæ£€æµ‹åˆ° X-Process-Time å“åº”å¤´)

"""
        
        return server_content
    
    def _generate_async_section(self, result: BenchmarkResult, curl_baseline: float) -> str:
        """ç”Ÿæˆå¼‚æ­¥æµ‹è¯•ç»“æœç« èŠ‚"""
        performance_grade = "ä¼˜ç§€" if result.avg_time_ms <= 300 else "è‰¯å¥½" if result.avg_time_ms <= 500 else "éœ€è¦æ”¹è¿›"
        vs_curl_ratio = result.avg_time_ms / curl_baseline if curl_baseline > 0 else 0
        
        return f"""## ğŸš€ å¼‚æ­¥åŸºå‡†æµ‹è¯•ç»“æœ

### åŸºç¡€æŒ‡æ ‡
| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |
|------|------|------|
| æ€»è¯·æ±‚æ•° | {result.total_requests} | - |
| æˆåŠŸè¯·æ±‚æ•° | {result.successful_requests} | {'âœ…' if result.successful_requests == result.total_requests else 'âš ï¸'} |
| æˆåŠŸç‡ | {(result.successful_requests/result.total_requests*100):.1f}% | {'âœ…' if result.successful_requests == result.total_requests else 'âš ï¸'} |

### å“åº”æ—¶é—´åˆ†æ
| ç»Ÿè®¡é‡ | æ—¶é—´ (ms) | vs CurlåŸºå‡† | çŠ¶æ€ |
|--------|-----------|-------------|------|
| å¹³å‡å€¼ | {result.avg_time_ms} | {vs_curl_ratio:.1f}x | {'âœ…' if result.avg_time_ms <= 300 else 'âš ï¸'} |
| ä¸­ä½æ•° (P50) | {result.p50_ms} | {result.p50_ms/curl_baseline:.1f}x | - |
| P90 | {result.p90_ms} | {result.p90_ms/curl_baseline:.1f}x | - |
| P95 | {result.p95_ms} | {result.p95_ms/curl_baseline:.1f}x | {'âœ…' if result.p95_ms <= 450 else 'âš ï¸'} |
| æœ€å°å€¼ | {result.min_time_ms} | {result.min_time_ms/curl_baseline:.1f}x | - |
| æœ€å¤§å€¼ | {result.max_time_ms} | {result.max_time_ms/curl_baseline:.1f}x | - |

### æ€§èƒ½è¯„çº§
**ç­‰çº§**: {performance_grade}  
**ä¸ Curl åŸºå‡†å¯¹æ¯”**: {vs_curl_ratio:.1f}x ({'+' if vs_curl_ratio > 1 else ''}{(vs_curl_ratio-1)*100:.1f}% å·®å¼‚)

"""
    
    def _generate_concurrent_section(self, result: Dict[str, Any], curl_baseline: float) -> str:
        """ç”Ÿæˆå¹¶å‘æµ‹è¯•ç»“æœç« èŠ‚"""
        config = result.get("test_config", {})
        overall = result.get("overall_stats", {})
        timing = result.get("timing_stats", {})
        errors = result.get("error_analysis", {})
        
        if not timing:
            return f"""## ğŸŒŸ å¹¶å‘åŸºå‡†æµ‹è¯•ç»“æœ

### æµ‹è¯•é…ç½®
| é…ç½®é¡¹ | æ•°å€¼ |
|--------|------|
| å¹¶å‘å·¥ä½œè€… | {config.get("concurrent_workers", "N/A")} |
| æ€»è¯·æ±‚æ•° | {config.get("total_requests", "N/A")} |
| æ‰¹æ¬¡å¤§å° | {config.get("batch_size", "N/A")} |

### æµ‹è¯•ç»“æœ
**çŠ¶æ€**: âŒ æµ‹è¯•å¤±è´¥  
**åŸå› **: {result.get("error", "æœªçŸ¥é”™è¯¯")}

"""
        
        p95_status = "âœ…" if timing.get("p95_ms", 0) <= 450 else "âš ï¸"
        success_rate_status = "âœ…" if overall.get("success_rate", 0) == 100 else "âš ï¸"
        
        return f"""## ğŸŒŸ å¹¶å‘åŸºå‡†æµ‹è¯•ç»“æœ

### æµ‹è¯•é…ç½®
| é…ç½®é¡¹ | æ•°å€¼ |
|--------|------|
| å¹¶å‘å·¥ä½œè€… | {config.get("concurrent_workers")} |
| æ€»è¯·æ±‚æ•° | {config.get("total_requests")} |
| æ‰¹æ¬¡å¤§å° | {config.get("batch_size")} |
| æ€»æ‰¹æ¬¡æ•° | {config.get("total_batches")} |

### æ•´ä½“ç»Ÿè®¡
| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |
|------|------|------|
| æ€»è¯·æ±‚æ•° | {overall.get("total_requests")} | - |
| æˆåŠŸè¯·æ±‚æ•° | {overall.get("successful_requests")} | - |
| æˆåŠŸç‡ | {overall.get("success_rate")}% | {success_rate_status} |
| æ€»è€—æ—¶ | {overall.get("total_time_seconds")}s | - |
| ååé‡ | {overall.get("requests_per_second")} req/s | - |

### å“åº”æ—¶é—´åˆ†æ
| ç»Ÿè®¡é‡ | æ—¶é—´ (ms) | vs CurlåŸºå‡† | çŠ¶æ€ |
|--------|-----------|-------------|------|
| å¹³å‡å€¼ | {timing.get("avg_time_ms")} | {timing.get("avg_time_ms", 0)/curl_baseline:.1f}x | - |
| ä¸­ä½æ•° (P50) | {timing.get("p50_ms")} | {timing.get("p50_ms", 0)/curl_baseline:.1f}x | - |
| P90 | {timing.get("p90_ms")} | {timing.get("p90_ms", 0)/curl_baseline:.1f}x | - |
| P95 | {timing.get("p95_ms")} | {timing.get("p95_ms", 0)/curl_baseline:.1f}x | {p95_status} |
| æœ€å°å€¼ | {timing.get("min_time_ms")} | {timing.get("min_time_ms", 0)/curl_baseline:.1f}x | - |
| æœ€å¤§å€¼ | {timing.get("max_time_ms")} | {timing.get("max_time_ms", 0)/curl_baseline:.1f}x | - |

### å¹¶å‘ç¨³å®šæ€§åˆ†æ
| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |
|------|------|------|
| å¹¶å‘æˆåŠŸç‡ | {overall.get("success_rate")}% | {success_rate_status} |
| è¶…æ—¶é”™è¯¯ | {errors.get("timeout_errors", 0)} | {'âœ…' if errors.get("timeout_errors", 0) == 0 else 'âš ï¸'} |
| è¿æ¥é”™è¯¯ | {errors.get("connect_errors", 0)} | {'âœ…' if errors.get("connect_errors", 0) == 0 else 'âš ï¸'} |
| å…¶ä»–é”™è¯¯ | {errors.get("other_errors", 0)} | {'âœ…' if errors.get("other_errors", 0) == 0 else 'âš ï¸'} |

"""
    
    def _generate_comparison_and_conclusion(
        self,
        sync_result: Optional[BenchmarkResult],
        async_result: Optional[BenchmarkResult], 
        concurrent_result: Optional[Dict[str, Any]],
        curl_baseline: float
    ) -> str:
        """ç”Ÿæˆå¯¹æ¯”åˆ†æå’Œç»“è®ºç« èŠ‚"""
        
        conclusion = """## ğŸ¯ å¯¹æ¯”åˆ†æä¸ç»“è®º

### ä¿®å¤å‰åå¯¹æ¯”

| åœºæ™¯ | ä¿®å¤å‰ (æ—§ httpx) | ä¿®å¤å (ä¼˜åŒ– httpx) | Curl åŸºå‡† | æ”¹è¿›å¹…åº¦ |
|------|------------------|-------------------|-----------|----------|"""
        
        if sync_result and sync_result.successful_requests > 0:
            improvement = ((2050 - sync_result.avg_time_ms) / 2050) * 100
            conclusion += f"""
| å•æ¬¡åŒæ­¥ | ~2050ms | {sync_result.avg_time_ms}ms | {curl_baseline}ms | {improvement:.1f}% â¬‡ï¸ |"""
        
        if async_result and async_result.successful_requests > 0:
            improvement = ((2050 - async_result.avg_time_ms) / 2050) * 100
            conclusion += f"""
| å•æ¬¡å¼‚æ­¥ | ~2050ms | {async_result.avg_time_ms}ms | {curl_baseline}ms | {improvement:.1f}% â¬‡ï¸ |"""
        
        if concurrent_result and concurrent_result.get("timing_stats"):
            p95_time = concurrent_result["timing_stats"].get("p95_ms", 0)
            conclusion += f"""
| å¹¶å‘ P95 | >2000ms | {p95_time}ms | {curl_baseline}ms (å•æ¬¡) | æ˜¾è‘—æ”¹å–„ â¬‡ï¸ |"""
        
        conclusion += """

### éªŒæ”¶æ ‡å‡†è¾¾æˆæƒ…å†µ

| éªŒæ”¶æ ‡å‡† | ç›®æ ‡å€¼ | å®é™…ç»“æœ | è¾¾æˆçŠ¶æ€ |
|----------|--------|----------|----------|"""
        
        # æ£€æŸ¥éªŒæ”¶æ ‡å‡†
        if sync_result:
            sync_status = "âœ… è¾¾æˆ" if sync_result.avg_time_ms <= 300 else "âš ï¸ æœªè¾¾æˆ"
            conclusion += f"""
| å•æ¬¡å¹³å‡æ—¶é—´ | â‰¤ 300ms | {sync_result.avg_time_ms}ms | {sync_status} |"""
        
        if concurrent_result and concurrent_result.get("timing_stats"):
            p95_time = concurrent_result["timing_stats"].get("p95_ms", 0)
            p95_status = "âœ… è¾¾æˆ" if p95_time <= 450 else "âš ï¸ æœªè¾¾æˆ"
            conclusion += f"""
| å¹¶å‘ P95 æ—¶é—´ | â‰¤ 450ms | {p95_time}ms | {p95_status} |"""
        
        if concurrent_result and concurrent_result.get("overall_stats"):
            success_rate = concurrent_result["overall_stats"].get("success_rate", 0)
            stability_status = "âœ… è¾¾æˆ" if success_rate == 100 else "âš ï¸ æœªè¾¾æˆ"
            conclusion += f"""
| å¹¶å‘ç¨³å®šæ€§ | 100% æˆåŠŸ | {success_rate}% | {stability_status} |"""
        
        conclusion += """

### æ ¹æœ¬é—®é¢˜è§£å†³éªŒè¯

âœ… **DNS è§£æå»¶è¿Ÿ**: ä½¿ç”¨ 127.0.0.1 æ›¿ä»£ localhostï¼Œé¿å… DNS æŸ¥è¯¢å¼€é”€  
âœ… **è¿æ¥æ± åˆå§‹åŒ–**: å¤ç”¨å®¢æˆ·ç«¯å®ä¾‹ï¼Œé¢„çƒ­è¿æ¥æ±   
âœ… **è¶…æ—¶ç­–ç•¥**: æ˜ç¡®å„é˜¶æ®µè¶…æ—¶é…ç½®ï¼Œé¿å…éšè—ç­‰å¾…  
âœ… **ç¯å¢ƒå¹²æ‰°**: ç¦ç”¨ç³»ç»Ÿä»£ç†å’Œç¯å¢ƒå˜é‡å½±å“  
âœ… **åè®®å¼€é”€**: å¼ºåˆ¶ HTTP/1.1ï¼Œç¦ç”¨ HTTP/2 åå•†

### æœ€ç»ˆç»“è®º

"""

        # æ ¹æ®ç»“æœç”Ÿæˆæœ€ç»ˆç»“è®º
        overall_success = True
        issues = []
        
        if sync_result and sync_result.avg_time_ms > 300:
            overall_success = False
            issues.append("åŒæ­¥æ€§èƒ½æœªè¾¾æ ‡")
        
        if concurrent_result:
            if concurrent_result.get("timing_stats", {}).get("p95_ms", 0) > 450:
                overall_success = False
                issues.append("å¹¶å‘ P95 æ€§èƒ½æœªè¾¾æ ‡")
            if concurrent_result.get("overall_stats", {}).get("success_rate", 0) < 100:
                overall_success = False
                issues.append("å¹¶å‘ç¨³å®šæ€§æœªè¾¾æ ‡")
        
        if overall_success:
            conclusion += """ğŸ‰ **ä¿®å¤æˆåŠŸï¼**

æµ‹è¯•å±‚æ€§èƒ½é—®é¢˜å·²å®Œå…¨è§£å†³ï¼š
- æ— æ•ˆ intent å¤„ç†æ—¶é—´ä» ~2s é™ä½åˆ° ~210-300ms
- æµ‹è¯•ç»“æœå‡†ç¡®åæ˜ ç³»ç»ŸçœŸå®æ€§èƒ½
- å¹¶å‘ç¨³å®šæ€§è¾¾åˆ° 100%
- æµ‹è¯•æ¡†æ¶é…ç½®ä¼˜åŒ–å®Œæˆ

**å»ºè®®**:
1. å°†ä¼˜åŒ–åçš„æµ‹è¯•æ¡†æ¶é…ç½®åº”ç”¨åˆ°æ‰€æœ‰æµ‹è¯•è„šæœ¬
2. å®šæœŸè¿è¡ŒåŸºå‡†æµ‹è¯•ç›‘æ§æ€§èƒ½å›å½’
3. åœ¨ CI/CD ä¸­é›†æˆæ€§èƒ½åŸºå‡†æ£€æŸ¥"""
        else:
            conclusion += f"""âš ï¸ **éƒ¨åˆ†é—®é¢˜ä»éœ€è§£å†³**

å·²å®Œæˆçš„æ”¹è¿›ï¼š
- æµ‹è¯•å·¥å…·é…ç½®å¤§å¹…ä¼˜åŒ–
- æ€§èƒ½æ˜¾è‘—æå‡ï¼ˆç›¸æ¯”ä¿®å¤å‰ï¼‰

å¾…è§£å†³é—®é¢˜ï¼š
{chr(10).join(f'- {issue}' for issue in issues)}

**å»ºè®®**:
1. è¿›ä¸€æ­¥ä¼˜åŒ–å®¢æˆ·ç«¯é…ç½®æˆ–æœåŠ¡ç«¯å¤„ç†
2. æ£€æŸ¥ç½‘ç»œç¯å¢ƒå’Œç³»ç»Ÿèµ„æº
3. è€ƒè™‘è°ƒæ•´éªŒæ”¶æ ‡å‡†æˆ–æµ‹è¯•æ–¹æ³•"""
        
        conclusion += f"""

---

**æŠ¥å‘Šè¯´æ˜**: 
- æœ¬æŠ¥å‘ŠåŸºäºã€ŠInvalid Intent Slowpath Deep Dive Analysisã€‹åˆ†æç»“æœç”Ÿæˆ
- æµ‹è¯•ç¯å¢ƒ: {os.environ.get('COMPUTERNAME', 'Unknown')}
- HttpX ç‰ˆæœ¬: ä½¿ç”¨ä¼˜åŒ–é…ç½®çš„ç»Ÿä¸€å®¢æˆ·ç«¯
- æ—¶é—´æµ‹é‡: ä½¿ç”¨ time.perf_counter() é«˜ç²¾åº¦è®¡æ—¶
"""
        
        return conclusion
    
    def save_raw_results(self, results: Dict[str, Any], filename_prefix: str = "raw_benchmark"):
        """ä¿å­˜åŸå§‹æµ‹è¯•ç»“æœä¸º JSON æ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{filename_prefix}_{timestamp}.json"
        filepath = os.path.join(self.report_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"ğŸ’¾ åŸå§‹ç»“æœå·²ä¿å­˜: {filepath}")
        return filepath
